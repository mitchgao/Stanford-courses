{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 11.9. Bayesian Neural Nets and the NIPS 2003 Challenge\n",
    "\n",
    "A classification competition was held in 2003, in which five labeled training datasets were provided to participants. It was organized for a Neural Information Processing Systems (NIPS) workshop. Each of the data sets consituted a two-class classification problems, which different sizes and from a variety of domains (see TABLE 11.2). Feature measurements for a validation dataset were also available.\n",
    "\n",
    "Participants developed and applied statistical learning procedures to make predictions on the datasets, and could submit predictions to a website on the validation set for a period of 12 weeks. With this feedback, participants were then asked to submit predictions for a separate test set and they received their results. Finally, the class labels for the validation set were released and participants had one week to train their final predictions to the competition website. A total of 75 groups participated, with 20 and 16 eventually making submissions on the validation and test sets, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TABLE 11.2. NIPS 2003 challenge data sets. The column labeled $p$ is the number of features. For the Dorothea dataset the features are binary. $N_{\\text{tr}}$, $N_{\\text{val}}$, and $N_{\\text{te}}$ are the number of training, validation and test cases, respectively.\n",
    "Dataset | Domain | Feature Type | $p$ | Percent Probes | $N_{\\text{tr}}$ | $N_{\\text{val}}$ | $N_{\\text{te}}$\n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "Arcene | Mass spectrometry | Dense | 10,000 | 30 | 100 | 100 | 700\n",
    "Dexter | Text classification | Sparse | 20,000 | 50 | 300 | 300 | 2000\n",
    "Dorothea | Drug discovery | Sparse | 100,000 | 50 | 800 | 350 | 800\n",
    "Gisette | Digit recognition | Dense | 5,000 | 30 | 6000 | 1000 | 6500\n",
    "Madelon | Artificial | Dense | 500 | 96 | 2000 | 600 | 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probes\n",
    "There was an emphasis on feature extraction in the competition. Artificial \"probes\" were added to the data: These are noise features with distributions resembling the real features but independent of the class labels. The percentage of probes that were added to each dataset, relative to the total set of features, is shown on TABLE 11.2. Thus each learning algorithm had to figure out a way of identifying the probes and downweighting or eliminating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Winners\n",
    "A number of metrics were used to evaluate the entries, including the percentage correct on the test set, the area under the ROC curve, and a combined score that compared each pair of classifiers head-to-head. The results of the competition are very interesting and are detailed in Guyon et al. (2006). The most notable result: the entries of Neal and Zhang (2006) were the clear overall winners. In the final competition they finished first in three of the five datasets, and were 5th and 7th on the remaining two datasets.\n",
    "\n",
    "In their winning entries, Neal and Zhang (2006) used a series of preprocessing feature-selection steps, followed by Bayesian neural networks, Dirichlet diffusion trees, and combinations of these methods. Here we focus only on the Bayesian neural network approach, and try to discern which aspects of their approach were important for its success. We rerun their programs and compare the results to boosted neural networks and boosted trees, and other related methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
