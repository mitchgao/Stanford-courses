{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 11.8. Discussion\n",
    "\n",
    "Both projection pursuit regression and neural networks take nonlinear functions of linear combinations (\"derived features\") of the inputs. This is a powerful and very general approach for regression and classification, and has been shown to compete well with the best learning methods on many problems.\n",
    "\n",
    "> These tools are especially effective in problems with a high SNR and settings where prediction without interpretation is the goal.\n",
    "\n",
    "> They are less effective for problems where the goal is to describe the physical process that generated the data and the roles of individual inputs.\n",
    "\n",
    "Each input enters into the model in many places, in a nonlinear fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efforts to comprehend the model\n",
    "\n",
    "Some authors (Hinton, 1989) plot a diagram of the estimated weights into each hidden unit, to try to understand the feature that each unit is extracting. This is limited however by the lack of identifiability of the parameter vectors $\\alpha_m$, $m=1,\\cdots,M$. Often there are solutions with $\\alpha_m$ spanning the same linear space as the ones found during training, giving predicted values that are roughly the same.\n",
    "\n",
    "Some authors suggest carrying out a principal component analysis of these weights, to try to find an interpretable solution.\n",
    "\n",
    "In general, the difficulty of interpreting these models has limited their use in fields like medicine, where interpretation of the model is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian inference\n",
    "\n",
    "There has been a great deal of research on the training of neural networks.\n",
    "\n",
    "Unlike methods like CART and MARS, neural networks are smooth functions of real-valued parameters. This facilitates the development of Bayesian inference for these models.\n",
    "\n",
    "The next sections discusses a successful Bayesian implementation of neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
