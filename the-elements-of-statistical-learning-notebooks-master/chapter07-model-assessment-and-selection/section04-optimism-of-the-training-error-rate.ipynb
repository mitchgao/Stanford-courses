{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 7.4. Optimism of the Training Error Rate\n",
    "\n",
    "Discussions of error rate estimation can be confusing, because we have to make clear which quantities are fixed and which are random. Before we continue, we need a few definitions, elaborating on the material of $\\S$ 7.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "Given a training set $\\mathcal{T} = \\{(x_1,y_1), (x_2,y_2), \\cdots, (x_N,y_N)\\}$ the generalization error of a model $f$ is\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Err}_\\mathcal{T} = \\text{E}_{X^0,Y^0}\\left[ L(Y^0, \\hat{f}(X^0)) \\mid \\mathcal{T}\\right].\n",
    "\\end{equation}\n",
    "\n",
    "Note that\n",
    "* the training set $\\mathcal{T}$ is fixed in the above expression,\n",
    "* the point $(X^0,Y^0)$ is a new test data point, drawn from $F$, the joint distribution of the data.\n",
    "\n",
    "Averaging over training sets $\\mathcal{T}$ yields the expected error\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Err} = \\text{E}_\\mathcal{T} \\text{E}_{X^0,Y^0}\\left[ L(Y^0, \\hat{f}(X^0)) \\mid \\mathcal{T}\\right],\n",
    "\\end{equation}\n",
    "\n",
    "which is more amenable to statistical analysis. As mentioned earlier, it turns out that most methods effectively estimate the expected error rather than $\\text{E}_\\mathcal{T}$; see $\\S$ 7.12 for more on this point.\n",
    "\n",
    "Now typically, the training error\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{\\text{err}} = \\frac{1}{N} \\sum_{i=1}^N L(y_i, \\hat{f}(x_i))\n",
    "\\end{equation}\n",
    "\n",
    "will be less than the true error $\\text{Err}_\\mathcal{T}$, because the same data is being used to fit the method and assess its error (see Exercise 2.9). A fitting method typically adapts to the training data, and hence the apparent or training error $\\overline{\\text{err}}$ will be an overly optimistic estimate of the generalization error $\\text{Err}_{\\mathcal{T}}$.\n",
    "\n",
    "Part of the discrepancy is due to where the evaluation points occur. The quantity $\\text{Err}_{\\mathcal{T}}$ can be thought ofas _extra-sample_ error, since the test input vectors don't need to coincide with the training input vectors. The nature of the optimism in $\\overline{\\text{err}}$ is easiest to understand when we focus instead on the _in-sample_ error\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Err}_{\\text{in}} = \\frac{1}{N} \\sum_{i=1}^N \\text{E}_{Y^0} \\left[ L(Y_i^0, \\hat{f}(x_i)) \\mid\\mathcal{T}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "The $Y^0$ notation indicates that we observe $N$ new response values at each of the training points $x_i$, $i=1,2,\\cdots,N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of optimism\n",
    "\n",
    "We define the _optimism_ as the difference between $\\text{Err}_{\\text{in}}$ and the training error $\\overline{\\text{err}}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{op} \\equiv \\text{Err}_{\\text{in}} - \\overline{\\text{err}}.\n",
    "\\end{equation}\n",
    "\n",
    "This is typically positive since $\\overline{\\text{err}}$ is usually biased downward as a estimate of prediction error.\n",
    "\n",
    "Finally, the average optimism is the expectation of the optimism over training sets\n",
    "\n",
    "\\begin{equation}\n",
    "\\omega \\equiv \\text{E}_\\mathbf{y}(\\text{op}).\n",
    "\\end{equation}\n",
    "\n",
    "Here the predictors in the training set are fixed, and the expectation is over the training set outcome values; hence we have used $\\text{E}_\\mathbf{y}$ instead on $\\text{E}_\\mathcal{T}$.\n",
    "\n",
    "We can usually estimate only the expected error $\\omega$ rather than $\\text{op}$, in the same way that we can estimate the expected error $\\text{Err}$ rather than the conditional error $\\text{Err}_\\mathcal{T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For squared error, 0-1 loss, and other loss functions, one can show quite generally that\n",
    "\n",
    "\\begin{equation}\n",
    "\\omega = \\frac{2}{N} \\sum_{i=1}^N \\text{Cov}(\\hat{y}_i, y_i).\n",
    "\\end{equation}\n",
    "\n",
    "> Thus the amount by which $\\overline{\\text{err}}$ underestimates the true error depends on how strongly $y_i$ affects its own prediction.\n",
    "\n",
    "> The harder we fit the data, the greater $\\text{Cov}(\\hat{y}_i, y_i)$ will be, thereby increasing the optimism.\n",
    "\n",
    "Exercise 7.4 proves this result for squared error loss where $\\hat{y}_i$ is the fitted value from the regression. For 0-1 loss, $\\hat{y}_i \\in\\{0,1\\}$ is the classification at $x_i$, and for entropy loss, $\\hat{y}_i\\in[0,1]$ is the fitted probability of class $1$ at $x_i$.\n",
    "\n",
    "In summary, We have the important relation\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{E}_\\mathbf{y}(\\text{Err}_\\text{in}) = \\text{E}_\\mathbf{y}(\\overline{\\text{err}}) + \\frac{2}{N} \\sum_{i=1}^N \\text{Cov}(\\hat{y}_i, y_i).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplication and implication\n",
    "\n",
    "This above relation simplifies if $\\hat{y}_i$ is obtained by a linear fit with $d$ inputs or basis functions. For example,\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^N \\text{Cov}(\\hat{y}_i, y_i) = d\\sigma_\\epsilon^2\n",
    "\\end{equation}\n",
    "\n",
    "for the additive error model $Y=f(X)+\\epsilon$, then so\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{E}_\\mathbf{y}(\\text{Err}_\\text{in}) = \\text{E}_\\mathbf{y}(\\overline{\\text{err}}) + 2\\cdot\\frac{d}{N} \\sigma_\\epsilon^2.\n",
    "\\end{equation}\n",
    "\n",
    "The above covariance sum is the basis for the definition of the _effective number of parameters_ discussed in $\\S$ 7.6.\n",
    "\n",
    "The optimism increases linearly with the number $d$ of inputs or basis functions we use, but decreases as the training sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two different ways\n",
    "\n",
    "An obvious way to estimate prediction error is to estimate the optimism and then add it to the training error $\\overline{\\text{err}}$. The methods described in the next section -- $C_p$, $\\text{AIC}$, $\\text{BIC}$ and others -- work in this way, for a special class of estimates that are linear in their parameters.\n",
    "\n",
    "In contrast, cross-validation and bootstrap methods are direct estimates of the extra-sample error $\\text{Err}$. These general tools can be used with any loss function, and with nonlinear, adaptive fitting techniques.\n",
    "\n",
    "In-sample error is not usually of direct interest since future values of the features are not likely to coincide with their training set values. But for comparison between models, in-sample error is convenient and often leads to effective model selection. The reason is that the relative (rather than absolute) size of the error is what matters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
