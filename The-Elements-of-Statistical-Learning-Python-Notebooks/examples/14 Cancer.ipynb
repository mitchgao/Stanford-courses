{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 Cancer\n",
    "Ramaswamy et al. (2001) present a difficult microarray classification problem, involving a training set of 144 patients with 14 different types of cancer, and a test set of 54 patients. Gene expression measurements were available for 16,063 genes. One gene per row, one sample per column.\n",
    "\n",
    "Cancer classes are labelled as follows:\n",
    "1.  breast, 2.  prostate, 3.  lung, 4.  collerectal, 5.  lymphoma, 6.  bladder, 7.  melanoma, 8.  uterus, 9.  leukemia, 10. renal, 11. pancreas, 12. ovary, 13. meso, 14. cns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# define commonly used colors\n",
    "GRAY1, GRAY4, PURPLE = '#231F20', '#646369', '#A020F0'\n",
    "BLUE, ORANGE, BLUE1 = '#57B5E8', '#E69E00', '#174A7E'\n",
    "# configure plot font family to Arial\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data/14cancer.npy.npz')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last column contains 'is test' flag\n",
    "is_test = data[:,-1].astype(int)\n",
    "data_test = data[is_test == 1, :]\n",
    "data_train = data[is_test == 0, :]\n",
    "# pre-last column contains class\n",
    "y_train = data_train[:, -2].astype(int)\n",
    "y_test = data_test[:, -2].astype(int)\n",
    "X_train = data_train[:, :-2]\n",
    "X_test = data_test[:, :-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Shrunken Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "ncc = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('ncc', NearestCentroid(shrink_threshold=4.5))]\n",
    ").fit(X_train, y_train)\n",
    "print(np.sum(y_test != ncc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=0, tol=1e-6, C=100000)\n",
    "svc.fit(X_train, y_train)\n",
    "print(np.sum(y_test != svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-penalized Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler().fit(np.vstack((X_train, X_test)))\n",
    "scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = scaler.transform(X_train)\n",
    "X_test1 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, D, VT = np.linalg.svd(X_train1, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = U@np.diag(D)\n",
    "R_test = X_test1@VT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-60df07cbf06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msigma\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m144\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msigma_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m144\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "R = X_train\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "priors = counts/y_train.size\n",
    "means = np.vstack([np.mean(R[y_train == i], axis=0) for i in classes])\n",
    "sigma = np.zeros(shape=(X_train.shape[1], X_train.shape[1]))\n",
    "for k, m in zip(classes, means):\n",
    "    R_class = R[y_train == k]\n",
    "    for i in range(R_class.shape[0]):\n",
    "        v = np.atleast_2d(R_class[i] - m).T\n",
    "        sigma += v@v.T\n",
    "sigma /= (144 - 14)\n",
    "sigma_inv = np.linalg.inv(sigma)\n",
    "\n",
    "result = np.zeros(shape=(144, 14))\n",
    "for k, m, p in zip(classes, means, priors):\n",
    "    m = np.atleast_2d(m).T\n",
    "    dis = R.T @ sigma_inv @ m - 0.5 * m.T @ sigma_inv @ m + np.log(p)\n",
    "    result[:,k-1:k] = dis\n",
    "np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2924.31132484]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver='eigen', shrinkage=0.001).fit(R, y_train)\n",
    "sigma = lda.covariance_\n",
    "means = lda.means_\n",
    "priors = lda.priors_\n",
    "sigma_inv = np.linalg.inv(sigma)\n",
    "\n",
    "\n",
    "#result = np.zeros(shape=(144, 14))\n",
    "#for k, m, p in zip(classes, means, priors):\n",
    "#    m = np.atleast_2d(m).T\n",
    "#    dis = R @ sigma_inv @ m - 0.5 * m.T @ sigma_inv @ m + np.log(p)\n",
    "#    result[:,k-1:k] = dis\n",
    "#np.argmax(result, axis=1) == y_train\n",
    "x = np.atleast_2d(R[0]).T\n",
    "m = np.atleast_2d(means[0]).T\n",
    "x.T @ sigma_inv @ m - 0.5*m.T@sigma_inv@m + np.log(priors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0 23\n",
      "0.10808080808080808 0 23\n",
      "0.11616161616161616 0 23\n",
      "0.12424242424242425 0 23\n",
      "0.13232323232323234 0 23\n",
      "0.14040404040404042 0 23\n",
      "0.1484848484848485 0 23\n",
      "0.15656565656565657 0 23\n",
      "0.16464646464646465 0 23\n",
      "0.17272727272727273 0 23\n",
      "0.1808080808080808 1 23\n",
      "0.18888888888888888 1 22\n",
      "0.19696969696969696 1 22\n",
      "0.20505050505050504 1 21\n",
      "0.21313131313131314 1 21\n",
      "0.22121212121212122 1 21\n",
      "0.2292929292929293 1 22\n",
      "0.23737373737373738 1 22\n",
      "0.24545454545454545 1 22\n",
      "0.2535353535353535 1 23\n",
      "0.26161616161616164 2 23\n",
      "0.2696969696969697 2 23\n",
      "0.2777777777777778 2 23\n",
      "0.28585858585858587 2 23\n",
      "0.29393939393939394 2 23\n",
      "0.302020202020202 2 23\n",
      "0.3101010101010101 2 23\n",
      "0.3181818181818182 2 23\n",
      "0.32626262626262625 2 23\n",
      "0.3343434343434344 2 23\n",
      "0.3424242424242424 3 23\n",
      "0.35050505050505054 3 23\n",
      "0.35858585858585856 3 23\n",
      "0.3666666666666667 3 23\n",
      "0.3747474747474747 3 23\n",
      "0.38282828282828285 4 23\n",
      "0.3909090909090909 4 23\n",
      "0.398989898989899 4 23\n",
      "0.407070707070707 4 23\n",
      "0.41515151515151516 4 24\n",
      "0.4232323232323232 4 24\n",
      "0.4313131313131313 4 25\n",
      "0.43939393939393945 5 25\n",
      "0.44747474747474747 5 25\n",
      "0.4555555555555556 5 25\n",
      "0.4636363636363636 5 25\n",
      "0.47171717171717176 5 25\n",
      "0.4797979797979798 5 25\n",
      "0.4878787878787879 5 25\n",
      "0.49595959595959593 5 25\n",
      "0.5040404040404041 5 25\n",
      "0.5121212121212121 5 25\n",
      "0.5202020202020202 6 25\n",
      "0.5282828282828282 6 25\n",
      "0.5363636363636364 6 25\n",
      "0.5444444444444444 6 25\n",
      "0.5525252525252525 6 25\n",
      "0.5606060606060607 6 25\n",
      "0.5686868686868687 6 25\n",
      "0.5767676767676768 7 25\n",
      "0.5848484848484848 7 25\n",
      "0.592929292929293 7 25\n",
      "0.601010101010101 7 25\n",
      "0.609090909090909 7 25\n",
      "0.6171717171717171 7 26\n",
      "0.6252525252525253 7 26\n",
      "0.6333333333333333 7 26\n",
      "0.6414141414141414 7 26\n",
      "0.6494949494949495 7 26\n",
      "0.6575757575757576 7 26\n",
      "0.6656565656565656 7 26\n",
      "0.6737373737373737 8 26\n",
      "0.6818181818181818 8 26\n",
      "0.6898989898989899 8 27\n",
      "0.6979797979797979 9 27\n",
      "0.706060606060606 9 27\n",
      "0.7141414141414141 9 28\n",
      "0.7222222222222222 10 28\n",
      "0.7303030303030302 11 28\n",
      "0.7383838383838384 11 29\n",
      "0.7464646464646464 12 29\n",
      "0.7545454545454545 12 28\n",
      "0.7626262626262627 12 28\n",
      "0.7707070707070707 12 28\n",
      "0.7787878787878788 12 28\n",
      "0.7868686868686868 13 28\n",
      "0.794949494949495 14 28\n",
      "0.803030303030303 15 28\n",
      "0.8111111111111111 16 28\n",
      "0.8191919191919191 16 28\n",
      "0.8272727272727273 17 28\n",
      "0.8353535353535353 18 29\n",
      "0.8434343434343434 18 29\n",
      "0.8515151515151514 18 30\n",
      "0.8595959595959596 18 30\n",
      "0.8676767676767676 18 30\n",
      "0.8757575757575757 18 30\n",
      "0.8838383838383839 20 30\n",
      "0.8919191919191919 21 30\n",
      "0.9 22 30\n"
     ]
    }
   ],
   "source": [
    "for shrinkage in np.linspace(0.1, 0.9, 100):\n",
    "    lda = LinearDiscriminantAnalysis(solver='eigen', shrinkage=shrinkage).fit(R, y_train)\n",
    "    print(shrinkage, np.sum((lda.predict(R) != y_train)), np.sum((lda.predict(R_test) != y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lda', LinearDiscriminantAnalysis(solver='eigen', shrinkage=0.5))]\n",
    ").fit(X_train, y_train)\n",
    "print(np.sum(y_test != lda.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-penalized multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 251\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(\n",
    "    multi_class='multinomial', \n",
    "    penalty='l1', \n",
    "    solver='saga', \n",
    "    max_iter=7000,\n",
    "    fit_intercept=True,\n",
    "    C=0.097\n",
    ")\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('logistic', lr)])\n",
    "pipeline.fit(X_train, y_train)    \n",
    "print(np.sum(y_test != pipeline.predict(X_test)), np.sum(np.sum(abs(lr.coef_), axis=0) != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-penalized multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 16063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrey/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(\n",
    "    multi_class='multinomial', \n",
    "    penalty='l2', \n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    fit_intercept=True,\n",
    "    C=0.097\n",
    ")\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('logistic', lr)])\n",
    "pipeline.fit(X_train, y_train)    \n",
    "print(np.sum(y_test != pipeline.predict(X_test)), np.sum(np.sum(abs(lr.coef_), axis=0) != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic-Net penalized multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    multi_class='multinomial', \n",
    "    penalty='elasticnet', \n",
    "    solver='saga', \n",
    "    max_iter=7000,\n",
    "    fit_intercept=True,\n",
    "    C=0.09,\n",
    "    l1_ratio=0.6\n",
    ")\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('logistic', lr)])\n",
    "pipeline.fit(X_train, y_train)    \n",
    "print(np.sum(y_test != pipeline.predict(X_test)), np.sum(np.sum(abs(lr.coef_), axis=0) != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (with Tensorflow GPU)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
